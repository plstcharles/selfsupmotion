batch_size: 256
optimizer: adam
learning_rate: 0.01
start_lr: 0.00001
final_lr: 0.000001
warmup_epochs: 4
max_epoch: 40
patience: 3
weight_decay: 0.0005
lars_wrapper: False
architecture: kpts_regressor
backbone: resnet50
dropout: 0
input_height: 224
tuple_length: 1
frame_offset: 1
tuple_offset: 1
exp_name: baseline_long_2
gpus: 1
num_workers: 4
seed: None
precision: 16
early_stop_metric: val_loss
